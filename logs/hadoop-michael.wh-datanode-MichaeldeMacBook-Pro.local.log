2018-01-23 18:17:39,539 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = michaeldemacbook-pro.local/30.28.160.77
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.5
STARTUP_MSG:   classpath = /Users/michael.wh/workspace/hadoop-2.7.5/etc/hadoop:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/common/lib/activation-1.1.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/common/lib/asm-3.2.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/common/lib/avro-1.7.4.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/common/lib/commons-cli-1.2.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/common/lib/commons-codec-1.4.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/common/lib/commons-collections-3.2.2.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/common/lib/commons-compress-1.4.1.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/common/lib/commons-configuration-1.6.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/common/lib/commons-digester-1.8.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/common/lib/commons-httpclient-3.1.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/common/lib/commons-io-2.4.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/common/lib/commons-lang-2.6.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/common/lib/commons-logging-1.1.3.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/common/lib/commons-math3-3.1.1.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/common/lib/commons-net-3.1.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/common/lib/curator-client-2.7.1.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/common/lib/curator-framework-2.7.1.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/common/lib/gson-2.2.4.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/common/lib/guava-11.0.2.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/common/lib/hadoop-annotations-2.7.5.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/common/lib/hadoop-auth-2.7.5.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/common/lib/hamcrest-core-1.3.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/common/lib/httpclient-4.2.5.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/common/lib/httpcore-4.2.5.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/common/lib/jersey-core-1.9.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/common/lib/jersey-json-1.9.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/common/lib/jersey-server-1.9.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/common/lib/jets3t-0.9.0.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/common/lib/jettison-1.1.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/common/lib/jetty-6.1.26.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/common/lib/jetty-util-6.1.26.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/common/lib/jsch-0.1.54.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/common/lib/jsp-api-2.1.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/common/lib/jsr305-3.0.0.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/common/lib/junit-4.11.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/common/lib/log4j-1.2.17.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/common/lib/mockito-all-1.8.5.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/common/lib/netty-3.6.2.Final.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/common/lib/paranamer-2.3.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/common/lib/servlet-api-2.5.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/common/lib/stax-api-1.0-2.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/common/lib/xmlenc-0.52.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/common/lib/xz-1.0.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/common/lib/zookeeper-3.4.6.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/common/hadoop-common-2.7.5-tests.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/common/hadoop-common-2.7.5.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/common/hadoop-nfs-2.7.5.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/hdfs:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/hdfs/lib/asm-3.2.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/hdfs/lib/commons-io-2.4.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/hdfs/lib/guava-11.0.2.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/hdfs/hadoop-hdfs-2.7.5-tests.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/hdfs/hadoop-hdfs-2.7.5.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.5.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/yarn/lib/activation-1.1.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/yarn/lib/aopalliance-1.0.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/yarn/lib/asm-3.2.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/yarn/lib/commons-cli-1.2.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/yarn/lib/commons-codec-1.4.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/yarn/lib/commons-io-2.4.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/yarn/lib/commons-lang-2.6.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/yarn/lib/guava-11.0.2.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/yarn/lib/guice-3.0.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/yarn/lib/javax.inject-1.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/yarn/lib/jersey-client-1.9.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/yarn/lib/jersey-core-1.9.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/yarn/lib/jersey-json-1.9.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/yarn/lib/jersey-server-1.9.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/yarn/lib/jettison-1.1.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/yarn/lib/jetty-6.1.26.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/yarn/lib/log4j-1.2.17.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/yarn/lib/servlet-api-2.5.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/yarn/lib/xz-1.0.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/yarn/hadoop-yarn-api-2.7.5.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.5.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.5.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/yarn/hadoop-yarn-client-2.7.5.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/yarn/hadoop-yarn-common-2.7.5.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/yarn/hadoop-yarn-registry-2.7.5.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.5.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/yarn/hadoop-yarn-server-common-2.7.5.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.5.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.5.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.5.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.5.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.5.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/mapreduce/lib/asm-3.2.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/mapreduce/lib/guice-3.0.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.5.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/mapreduce/lib/javax.inject-1.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/mapreduce/lib/junit-4.11.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/mapreduce/lib/xz-1.0.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.5.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.5.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.5.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.5.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.5.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.5-tests.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.5.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.5.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.5.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://shv@git-wip-us.apache.org/repos/asf/hadoop.git -r 18065c2b6806ed4aa6a3187d77cbe21bb3dba075; compiled by 'kshvachk' on 2017-12-16T01:06Z
STARTUP_MSG:   java = 1.8.0_101
************************************************************/
2018-01-23 18:17:39,550 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2018-01-23 18:17:39,891 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2018-01-23 18:17:40,195 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2018-01-23 18:17:40,262 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2018-01-23 18:17:40,262 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2018-01-23 18:17:40,268 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2018-01-23 18:17:40,273 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is 30.28.160.77
2018-01-23 18:17:40,280 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2018-01-23 18:17:40,314 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:50010
2018-01-23 18:17:40,316 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwith is 1048576 bytes/s
2018-01-23 18:17:40,316 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 5
2018-01-23 18:17:40,395 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2018-01-23 18:17:40,406 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2018-01-23 18:17:40,413 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2018-01-23 18:17:40,417 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2018-01-23 18:17:40,419 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2018-01-23 18:17:40,419 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2018-01-23 18:17:40,419 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2018-01-23 18:17:40,434 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50733
2018-01-23 18:17:40,434 INFO org.mortbay.log: jetty-6.1.26
2018-01-23 18:17:40,592 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:50733
2018-01-23 18:17:40,700 INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:50075
2018-01-23 18:17:40,840 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = michael.wh
2018-01-23 18:17:40,840 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2018-01-23 18:17:40,898 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000
2018-01-23 18:17:40,921 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 50020
2018-01-23 18:17:41,043 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:50020
2018-01-23 18:17:41,056 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2018-01-23 18:17:41,077 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: <default>
2018-01-23 18:17:41,088 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:9000 starting to offer service
2018-01-23 18:17:41,095 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2018-01-23 18:17:41,097 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2018-01-23 18:17:42,214 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:17:43,218 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:17:44,223 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:17:45,227 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:17:46,232 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:17:47,236 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:17:48,239 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:17:49,243 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:17:50,248 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:17:51,253 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:17:51,258 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2018-01-23 18:17:57,264 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:17:58,265 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:17:59,271 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:18:00,276 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:18:01,282 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:18:02,284 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:18:03,286 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:18:04,292 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:18:05,297 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:18:06,299 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:18:06,303 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2018-01-23 18:18:12,313 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:18:13,320 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:18:14,326 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:18:15,332 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:18:16,338 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:18:17,341 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:18:18,348 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:18:19,354 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:18:20,360 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:18:21,364 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:18:21,732 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2018-01-23 18:18:27,741 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:18:28,743 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:18:29,745 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:18:30,751 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:18:31,755 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:18:32,760 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:18:33,762 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:18:34,768 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:18:35,773 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:18:36,778 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:18:36,782 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2018-01-23 18:18:42,789 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:18:43,791 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:18:44,793 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:18:45,798 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:18:46,800 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:18:47,804 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:18:48,807 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:18:49,809 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:18:50,814 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:18:51,819 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:18:51,823 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2018-01-23 18:18:57,834 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:18:58,839 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:18:59,843 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:19:00,848 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:19:01,852 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:19:02,856 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:19:03,858 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:19:04,864 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:19:05,870 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:19:06,876 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:19:06,880 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2018-01-23 18:19:12,888 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:19:13,890 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:19:14,895 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:19:15,898 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:19:16,903 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:19:17,908 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:19:18,912 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:19:19,916 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:19:20,920 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:19:21,922 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:19:21,926 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2018-01-23 18:19:27,933 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:19:28,937 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:19:29,942 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:19:30,944 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:19:31,950 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:19:32,954 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:19:33,959 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:19:34,963 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:19:35,965 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:19:36,970 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:19:36,973 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2018-01-23 18:19:42,980 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:19:43,983 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:19:44,990 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:19:45,993 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:19:46,998 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:19:48,001 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:19:49,007 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:19:50,010 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:19:51,015 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:19:52,016 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:19:52,019 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2018-01-23 18:19:58,027 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:19:59,029 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:20:00,031 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:20:01,036 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:20:02,043 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:20:03,048 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:20:04,054 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:20:05,056 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:20:06,062 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:20:07,066 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:20:07,070 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2018-01-23 18:20:13,075 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:20:14,077 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:20:15,081 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:20:16,082 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:20:17,088 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:20:18,091 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:20:19,096 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:20:20,099 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:20:21,101 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:20:22,107 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:20:22,426 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2018-01-23 18:20:28,436 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:20:29,439 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:20:30,445 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:20:31,451 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:20:32,456 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:20:33,458 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:20:34,463 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:20:35,469 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:20:36,472 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:20:37,474 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:20:37,478 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2018-01-23 18:20:43,486 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:20:44,493 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:20:45,495 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:20:46,501 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:20:47,503 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:20:48,506 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:20:49,510 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:20:50,516 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:20:51,517 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:20:52,523 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:20:52,528 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2018-01-23 18:20:58,538 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:20:59,541 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:21:00,545 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:21:01,549 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:21:02,550 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:21:03,551 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:21:04,557 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:21:05,559 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:21:06,565 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:21:07,566 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:21:07,570 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2018-01-23 18:21:13,578 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:21:14,582 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:21:15,587 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:21:16,593 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:21:17,598 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:21:18,604 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:21:19,606 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:21:20,609 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:21:21,612 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:21:22,618 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:21:22,621 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2018-01-23 18:21:28,633 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:21:29,634 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:21:30,641 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:21:31,646 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:21:32,651 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:21:33,653 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:21:34,659 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:21:35,661 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:21:36,667 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:21:37,670 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:21:37,672 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2018-01-23 18:21:43,680 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:21:44,682 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:21:45,686 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:21:46,691 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:21:47,694 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:21:48,699 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:21:49,701 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:21:50,707 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:21:51,709 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:21:52,715 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:21:52,719 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2018-01-23 18:21:58,722 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:21:59,726 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:22:00,730 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:22:01,732 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:22:02,739 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:22:03,741 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:22:04,745 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:22:05,748 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:22:06,753 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:22:07,758 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:22:07,761 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2018-01-23 18:22:13,767 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:22:14,774 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:22:15,775 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:22:16,777 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:22:17,780 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:22:18,784 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:22:19,788 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:22:20,791 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:22:21,793 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:22:22,799 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:22:23,162 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2018-01-23 18:22:29,169 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:22:30,175 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:22:31,176 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:22:32,181 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:22:33,183 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:22:34,189 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:22:35,194 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:22:36,197 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:22:37,200 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:22:38,201 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:22:38,205 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2018-01-23 18:22:44,214 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:22:45,220 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:22:46,224 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:22:47,228 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:22:48,235 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:22:49,237 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:22:50,240 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:22:51,247 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:22:52,250 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:22:53,254 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:22:53,258 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2018-01-23 18:22:59,266 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:23:00,270 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:23:01,271 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:23:02,275 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:23:03,277 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:23:04,278 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:23:05,283 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:23:06,288 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:23:07,290 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:23:08,293 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:23:08,297 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2018-01-23 18:23:14,303 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:23:15,306 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:23:16,312 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:23:17,319 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:23:18,324 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:23:19,328 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:23:20,333 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:23:21,339 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:23:22,344 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:23:23,349 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:23:23,353 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2018-01-23 18:23:29,363 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:23:30,369 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:23:31,372 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:23:32,374 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:23:33,380 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:23:34,383 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:23:35,389 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:23:36,396 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:23:37,399 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:23:38,403 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:23:38,406 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2018-01-23 18:23:44,417 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:23:45,420 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:23:46,422 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:23:47,428 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:23:48,433 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:23:49,437 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:23:50,439 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:23:51,445 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:23:52,450 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:23:53,455 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:23:53,458 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2018-01-23 18:23:59,462 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:24:00,467 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:24:01,471 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:24:02,476 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:24:03,478 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:24:04,484 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:24:05,485 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:24:06,490 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:24:07,493 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:24:08,499 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:24:08,503 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2018-01-23 18:24:14,509 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:24:15,515 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:24:16,516 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:24:17,522 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:24:18,525 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:24:19,528 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:24:20,531 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:24:21,535 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:24:22,541 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:24:23,546 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:24:23,830 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2018-01-23 18:24:29,834 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:24:30,840 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:24:31,841 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:24:32,844 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:24:33,847 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:24:34,854 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:24:35,856 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:24:36,859 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:24:37,865 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:24:38,868 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:24:38,871 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2018-01-23 18:24:44,878 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:24:45,880 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:24:46,886 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:24:47,887 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:24:48,892 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:24:49,894 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:24:50,898 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:24:51,904 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:24:52,906 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:24:53,911 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:24:53,915 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2018-01-23 18:24:59,924 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:25:00,929 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:25:01,933 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:25:02,936 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:25:03,942 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:25:04,949 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:25:05,951 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:25:06,956 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:25:07,962 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:25:08,966 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:25:08,968 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2018-01-23 18:25:14,976 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:25:15,981 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:25:16,982 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:25:17,985 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:25:18,989 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:25:19,994 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:25:20,999 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:25:22,002 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:25:23,007 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:25:24,012 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:25:24,014 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2018-01-23 18:25:30,020 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:25:31,025 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:25:32,031 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:25:33,037 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:25:34,040 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:25:35,046 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:25:36,051 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:25:37,056 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:25:38,058 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:25:39,064 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:25:39,067 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2018-01-23 18:25:45,071 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:25:46,077 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:25:47,080 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:25:48,086 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:25:49,088 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:25:50,094 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:25:51,096 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:25:52,102 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:25:53,104 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:25:54,106 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:25:54,109 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2018-01-23 18:26:00,119 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:26:01,124 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:26:02,125 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:26:03,130 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:26:04,132 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:26:05,135 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:26:06,139 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:26:07,146 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:26:08,148 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:26:09,155 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:26:09,161 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2018-01-23 18:26:15,166 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:26:16,172 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:26:17,175 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:26:18,180 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:26:19,182 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:26:20,188 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:26:21,193 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:26:22,197 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:26:23,201 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:26:24,205 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:26:24,552 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2018-01-23 18:26:30,562 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:26:31,566 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:26:32,570 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:26:33,575 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:26:34,577 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:26:35,578 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:26:36,582 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:26:37,584 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:26:38,587 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:26:39,589 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:26:39,593 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2018-01-23 18:26:45,600 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:26:46,602 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:26:47,604 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:26:48,609 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:26:49,610 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:26:50,612 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:26:51,617 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:26:52,621 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:26:53,626 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:26:54,629 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:26:54,633 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2018-01-23 18:27:00,641 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:27:01,644 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:27:02,648 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:27:03,650 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:27:04,654 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:27:05,658 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:27:06,663 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:27:07,666 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:27:08,669 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:27:09,672 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:27:09,675 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2018-01-23 18:27:15,680 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:27:16,686 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:27:17,689 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:27:18,694 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:27:19,695 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:27:20,698 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:27:21,701 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:27:22,704 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:27:23,709 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:27:24,712 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:27:24,716 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2018-01-23 18:27:30,722 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:27:31,726 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:27:32,731 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:27:33,735 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:27:34,739 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:27:35,743 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:27:36,749 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:27:37,752 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:27:38,756 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:27:39,760 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:27:39,765 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2018-01-23 18:27:45,773 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:27:46,779 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:27:47,782 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:27:48,788 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:27:49,790 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:27:50,796 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:27:51,797 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:27:52,802 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:27:53,804 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:27:54,810 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:27:54,814 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2018-01-23 18:28:00,823 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:28:01,827 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:28:02,829 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:28:03,835 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:28:04,839 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:28:05,844 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:28:06,850 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:28:07,852 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:28:08,859 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:28:09,862 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:28:09,866 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2018-01-23 18:28:15,875 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:28:16,878 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:28:17,884 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:28:18,889 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:28:19,894 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:28:20,895 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:28:21,901 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:28:22,904 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:28:23,909 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:28:24,911 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:28:25,193 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2018-01-23 18:28:31,202 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:28:32,207 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:28:33,211 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:28:34,213 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:28:35,218 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:28:36,223 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:28:37,227 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:28:38,231 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:28:39,237 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:28:40,242 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:28:40,245 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2018-01-23 18:28:46,253 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:28:47,258 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:28:48,259 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:28:49,260 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:28:50,266 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:28:51,272 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:28:52,275 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:28:53,280 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:28:54,283 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:28:55,288 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:28:55,291 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2018-01-23 18:29:01,297 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:29:02,303 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:29:03,307 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:29:04,308 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:29:05,313 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:29:06,318 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:29:07,321 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:29:08,327 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:29:09,332 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:29:10,339 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:29:10,343 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2018-01-23 18:29:16,352 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:29:17,354 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:29:18,356 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:29:19,361 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:29:20,364 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:29:21,369 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:29:22,375 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:29:23,379 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:29:24,380 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:29:25,381 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:29:25,385 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2018-01-23 18:29:31,391 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:29:32,394 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:29:33,399 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:29:34,403 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:29:35,407 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:29:36,408 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:29:37,414 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:29:38,416 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:29:39,419 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:29:40,423 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:29:40,426 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2018-01-23 18:29:46,430 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:29:47,436 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:29:48,441 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:29:49,444 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:29:50,447 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:29:51,448 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:29:52,452 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:29:53,455 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:29:54,460 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:29:55,466 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:29:55,470 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2018-01-23 18:30:01,476 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:30:02,480 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:30:03,486 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:30:04,492 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:30:05,495 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:30:06,500 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:30:07,502 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:30:08,508 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:30:09,514 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:30:10,520 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:30:10,523 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2018-01-23 18:30:16,526 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:30:17,530 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:30:17,592 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: RECEIVED SIGNAL 15: SIGTERM
2018-01-23 18:30:17,597 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at michaeldemacbook-pro.local/30.28.160.77
************************************************************/
2018-01-23 18:31:11,440 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = michaeldemacbook-pro.local/30.28.160.77
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.5
STARTUP_MSG:   classpath = /Users/michael.wh/workspace/hadoop-2.7.5/etc/hadoop:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/common/lib/activation-1.1.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/common/lib/asm-3.2.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/common/lib/avro-1.7.4.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/common/lib/commons-cli-1.2.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/common/lib/commons-codec-1.4.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/common/lib/commons-collections-3.2.2.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/common/lib/commons-compress-1.4.1.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/common/lib/commons-configuration-1.6.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/common/lib/commons-digester-1.8.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/common/lib/commons-httpclient-3.1.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/common/lib/commons-io-2.4.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/common/lib/commons-lang-2.6.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/common/lib/commons-logging-1.1.3.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/common/lib/commons-math3-3.1.1.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/common/lib/commons-net-3.1.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/common/lib/curator-client-2.7.1.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/common/lib/curator-framework-2.7.1.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/common/lib/gson-2.2.4.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/common/lib/guava-11.0.2.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/common/lib/hadoop-annotations-2.7.5.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/common/lib/hadoop-auth-2.7.5.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/common/lib/hamcrest-core-1.3.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/common/lib/httpclient-4.2.5.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/common/lib/httpcore-4.2.5.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/common/lib/jersey-core-1.9.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/common/lib/jersey-json-1.9.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/common/lib/jersey-server-1.9.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/common/lib/jets3t-0.9.0.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/common/lib/jettison-1.1.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/common/lib/jetty-6.1.26.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/common/lib/jetty-util-6.1.26.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/common/lib/jsch-0.1.54.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/common/lib/jsp-api-2.1.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/common/lib/jsr305-3.0.0.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/common/lib/junit-4.11.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/common/lib/log4j-1.2.17.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/common/lib/mockito-all-1.8.5.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/common/lib/netty-3.6.2.Final.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/common/lib/paranamer-2.3.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/common/lib/servlet-api-2.5.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/common/lib/stax-api-1.0-2.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/common/lib/xmlenc-0.52.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/common/lib/xz-1.0.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/common/lib/zookeeper-3.4.6.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/common/hadoop-common-2.7.5-tests.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/common/hadoop-common-2.7.5.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/common/hadoop-nfs-2.7.5.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/hdfs:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/hdfs/lib/asm-3.2.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/hdfs/lib/commons-io-2.4.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/hdfs/lib/guava-11.0.2.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/hdfs/hadoop-hdfs-2.7.5-tests.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/hdfs/hadoop-hdfs-2.7.5.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.5.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/yarn/lib/activation-1.1.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/yarn/lib/aopalliance-1.0.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/yarn/lib/asm-3.2.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/yarn/lib/commons-cli-1.2.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/yarn/lib/commons-codec-1.4.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/yarn/lib/commons-io-2.4.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/yarn/lib/commons-lang-2.6.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/yarn/lib/guava-11.0.2.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/yarn/lib/guice-3.0.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/yarn/lib/javax.inject-1.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/yarn/lib/jersey-client-1.9.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/yarn/lib/jersey-core-1.9.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/yarn/lib/jersey-json-1.9.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/yarn/lib/jersey-server-1.9.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/yarn/lib/jettison-1.1.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/yarn/lib/jetty-6.1.26.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/yarn/lib/log4j-1.2.17.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/yarn/lib/servlet-api-2.5.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/yarn/lib/xz-1.0.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/yarn/hadoop-yarn-api-2.7.5.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.5.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.5.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/yarn/hadoop-yarn-client-2.7.5.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/yarn/hadoop-yarn-common-2.7.5.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/yarn/hadoop-yarn-registry-2.7.5.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.5.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/yarn/hadoop-yarn-server-common-2.7.5.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.5.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.5.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.5.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.5.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.5.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/mapreduce/lib/asm-3.2.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/mapreduce/lib/guice-3.0.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.5.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/mapreduce/lib/javax.inject-1.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/mapreduce/lib/junit-4.11.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/mapreduce/lib/xz-1.0.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.5.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.5.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.5.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.5.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.5.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.5-tests.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.5.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.5.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.5.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://shv@git-wip-us.apache.org/repos/asf/hadoop.git -r 18065c2b6806ed4aa6a3187d77cbe21bb3dba075; compiled by 'kshvachk' on 2017-12-16T01:06Z
STARTUP_MSG:   java = 1.8.0_101
************************************************************/
2018-01-23 18:31:11,450 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2018-01-23 18:31:11,805 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2018-01-23 18:31:12,123 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2018-01-23 18:31:12,201 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2018-01-23 18:31:12,201 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2018-01-23 18:31:12,206 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2018-01-23 18:31:12,210 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is 30.28.160.77
2018-01-23 18:31:12,219 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2018-01-23 18:31:12,255 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:50010
2018-01-23 18:31:12,257 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwith is 1048576 bytes/s
2018-01-23 18:31:12,257 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 5
2018-01-23 18:31:12,347 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2018-01-23 18:31:12,355 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2018-01-23 18:31:12,362 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2018-01-23 18:31:12,367 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2018-01-23 18:31:12,369 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2018-01-23 18:31:12,369 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2018-01-23 18:31:12,369 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2018-01-23 18:31:12,386 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 51777
2018-01-23 18:31:12,386 INFO org.mortbay.log: jetty-6.1.26
2018-01-23 18:31:12,571 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:51777
2018-01-23 18:31:12,677 INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:50075
2018-01-23 18:31:12,829 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = michael.wh
2018-01-23 18:31:12,829 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2018-01-23 18:31:12,867 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000
2018-01-23 18:31:12,884 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 50020
2018-01-23 18:31:12,990 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:50020
2018-01-23 18:31:13,002 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2018-01-23 18:31:13,023 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: <default>
2018-01-23 18:31:13,035 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:9000 starting to offer service
2018-01-23 18:31:13,041 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2018-01-23 18:31:13,042 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2018-01-23 18:31:14,136 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:31:15,142 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:31:16,146 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:31:17,151 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:31:18,153 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:31:19,159 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:31:20,163 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:31:21,169 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:31:22,175 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:31:23,180 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:31:23,185 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2018-01-23 18:31:29,192 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:31:30,198 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:31:31,204 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:31:32,209 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:31:33,211 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:31:34,217 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:31:35,223 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:31:36,227 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:31:37,233 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:31:38,238 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:31:38,241 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2018-01-23 18:31:44,253 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:31:45,255 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:31:46,258 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:31:47,265 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:31:48,267 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:31:49,271 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:31:50,276 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:31:51,277 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:31:52,283 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:31:53,286 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:31:53,290 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2018-01-23 18:31:59,293 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:32:00,297 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:32:01,303 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:32:02,305 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:32:03,311 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:32:04,316 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:32:05,322 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:32:06,324 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:32:07,330 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:32:08,335 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:32:08,339 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2018-01-23 18:32:14,346 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:32:15,347 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:32:16,352 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:32:17,354 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:32:18,355 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:32:19,360 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:32:20,364 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:32:21,370 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:32:22,375 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:32:23,380 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:32:23,384 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2018-01-23 18:32:29,391 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:32:30,398 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:32:31,403 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:32:32,405 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:32:33,409 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:32:34,410 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:32:35,415 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:32:36,416 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:32:37,423 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:32:38,427 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:32:38,432 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2018-01-23 18:32:44,440 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:32:45,444 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:32:46,450 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:32:47,454 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:32:48,456 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:32:49,462 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:32:50,464 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:32:51,468 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:32:52,474 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:32:53,479 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:32:53,482 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2018-01-23 18:32:59,489 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:33:00,494 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:33:01,497 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:33:02,501 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:33:03,502 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:33:04,507 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:33:05,512 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:33:06,517 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:33:07,522 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:33:08,524 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:33:08,868 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2018-01-23 18:33:14,877 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:33:15,881 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:33:16,885 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:33:17,889 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:33:18,895 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:33:19,897 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:33:20,901 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:33:21,906 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:33:22,908 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:33:23,914 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:33:23,919 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2018-01-23 18:33:29,930 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:33:30,936 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:33:31,937 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:33:32,942 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:33:33,945 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:33:34,949 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:33:35,955 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:33:36,959 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:33:37,965 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:33:38,970 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:33:38,974 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2018-01-23 18:33:44,985 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:33:45,990 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:33:46,996 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:33:47,998 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:33:49,002 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:33:50,004 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:33:51,005 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:33:52,006 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:33:53,010 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:33:54,013 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:33:54,018 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2018-01-23 18:34:00,024 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:34:01,026 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:34:02,032 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:34:03,035 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:34:04,041 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:34:05,043 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:34:06,048 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:34:07,054 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:34:08,058 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:34:09,063 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:34:09,067 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2018-01-23 18:34:15,074 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:34:16,080 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:34:17,083 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:34:18,089 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:34:19,093 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:34:20,098 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:34:21,101 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:34:22,107 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:34:23,110 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:34:24,115 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:34:24,118 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2018-01-23 18:34:30,126 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:34:31,128 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:34:32,133 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:34:33,139 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:34:34,145 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:34:35,150 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:34:36,155 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:34:37,161 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:34:38,165 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:34:39,170 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:34:39,174 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2018-01-23 18:34:45,184 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:34:46,189 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:34:47,190 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:34:48,196 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:34:49,200 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:34:50,204 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:34:51,209 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:34:52,212 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:34:53,216 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:34:54,221 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:34:54,225 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2018-01-23 18:35:00,235 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:35:01,238 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:35:02,244 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:35:03,248 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:35:04,253 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:35:05,258 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:35:06,261 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:35:07,264 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:35:08,269 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:35:09,272 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:35:09,560 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2018-01-23 18:35:15,565 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:35:16,566 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:35:17,570 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:35:18,574 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:35:19,576 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:35:20,578 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:35:21,583 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:35:22,589 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:35:23,594 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:35:24,595 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:35:24,598 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2018-01-23 18:35:30,605 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:35:31,608 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:35:32,613 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:35:33,615 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:35:34,622 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:35:35,626 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:35:36,631 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:35:37,635 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:35:38,639 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:35:39,642 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:35:39,646 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2018-01-23 18:35:45,656 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:35:46,662 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:35:47,667 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:35:48,673 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:35:49,675 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:35:50,678 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:35:51,682 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:35:52,688 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:35:53,692 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:35:54,698 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:35:54,701 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2018-01-23 18:36:00,707 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:36:01,713 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:36:02,715 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:36:03,716 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:36:04,722 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:36:05,727 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:36:06,729 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:36:07,734 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:36:08,739 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:36:09,742 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:36:09,746 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2018-01-23 18:36:15,755 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:36:16,760 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:36:17,762 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:36:18,766 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:36:19,767 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:36:20,771 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:36:21,776 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:36:22,780 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:36:23,784 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:36:24,790 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:36:24,797 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2018-01-23 18:36:30,806 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:36:31,812 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:36:32,814 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:36:33,816 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:36:34,819 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:36:35,824 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:36:36,829 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:36:37,834 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:36:38,839 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:36:39,841 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:36:39,845 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2018-01-23 18:36:45,853 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:36:46,859 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:36:47,864 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:36:48,868 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:36:49,873 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:36:50,877 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:36:51,881 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:36:52,883 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:36:53,884 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:36:54,891 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:36:54,897 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2018-01-23 18:37:00,903 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:37:01,907 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:37:02,912 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:37:03,915 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:37:04,922 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:37:05,924 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:37:06,929 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:37:07,935 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:37:08,940 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:37:09,945 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:37:09,950 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2018-01-23 18:37:15,956 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:37:16,962 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:37:17,963 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:37:18,969 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:37:19,972 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:37:20,977 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:37:21,980 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:37:22,981 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:37:23,986 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:37:24,991 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2018-01-23 18:37:24,995 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2018-01-23 18:37:29,230 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: RECEIVED SIGNAL 15: SIGTERM
2018-01-23 18:37:29,232 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at michaeldemacbook-pro.local/30.28.160.77
************************************************************/
2018-01-23 18:38:29,324 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = michaeldemacbook-pro.local/30.28.160.77
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.5
STARTUP_MSG:   classpath = /Users/michael.wh/workspace/hadoop-2.7.5/etc/hadoop:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/common/lib/activation-1.1.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/common/lib/asm-3.2.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/common/lib/avro-1.7.4.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/common/lib/commons-cli-1.2.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/common/lib/commons-codec-1.4.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/common/lib/commons-collections-3.2.2.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/common/lib/commons-compress-1.4.1.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/common/lib/commons-configuration-1.6.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/common/lib/commons-digester-1.8.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/common/lib/commons-httpclient-3.1.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/common/lib/commons-io-2.4.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/common/lib/commons-lang-2.6.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/common/lib/commons-logging-1.1.3.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/common/lib/commons-math3-3.1.1.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/common/lib/commons-net-3.1.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/common/lib/curator-client-2.7.1.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/common/lib/curator-framework-2.7.1.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/common/lib/gson-2.2.4.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/common/lib/guava-11.0.2.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/common/lib/hadoop-annotations-2.7.5.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/common/lib/hadoop-auth-2.7.5.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/common/lib/hamcrest-core-1.3.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/common/lib/httpclient-4.2.5.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/common/lib/httpcore-4.2.5.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/common/lib/jersey-core-1.9.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/common/lib/jersey-json-1.9.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/common/lib/jersey-server-1.9.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/common/lib/jets3t-0.9.0.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/common/lib/jettison-1.1.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/common/lib/jetty-6.1.26.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/common/lib/jetty-util-6.1.26.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/common/lib/jsch-0.1.54.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/common/lib/jsp-api-2.1.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/common/lib/jsr305-3.0.0.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/common/lib/junit-4.11.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/common/lib/log4j-1.2.17.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/common/lib/mockito-all-1.8.5.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/common/lib/netty-3.6.2.Final.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/common/lib/paranamer-2.3.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/common/lib/servlet-api-2.5.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/common/lib/stax-api-1.0-2.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/common/lib/xmlenc-0.52.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/common/lib/xz-1.0.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/common/lib/zookeeper-3.4.6.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/common/hadoop-common-2.7.5-tests.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/common/hadoop-common-2.7.5.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/common/hadoop-nfs-2.7.5.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/hdfs:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/hdfs/lib/asm-3.2.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/hdfs/lib/commons-io-2.4.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/hdfs/lib/guava-11.0.2.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/hdfs/hadoop-hdfs-2.7.5-tests.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/hdfs/hadoop-hdfs-2.7.5.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.5.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/yarn/lib/activation-1.1.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/yarn/lib/aopalliance-1.0.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/yarn/lib/asm-3.2.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/yarn/lib/commons-cli-1.2.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/yarn/lib/commons-codec-1.4.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/yarn/lib/commons-io-2.4.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/yarn/lib/commons-lang-2.6.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/yarn/lib/guava-11.0.2.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/yarn/lib/guice-3.0.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/yarn/lib/javax.inject-1.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/yarn/lib/jersey-client-1.9.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/yarn/lib/jersey-core-1.9.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/yarn/lib/jersey-json-1.9.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/yarn/lib/jersey-server-1.9.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/yarn/lib/jettison-1.1.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/yarn/lib/jetty-6.1.26.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/yarn/lib/log4j-1.2.17.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/yarn/lib/servlet-api-2.5.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/yarn/lib/xz-1.0.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/yarn/hadoop-yarn-api-2.7.5.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.5.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.5.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/yarn/hadoop-yarn-client-2.7.5.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/yarn/hadoop-yarn-common-2.7.5.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/yarn/hadoop-yarn-registry-2.7.5.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.5.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/yarn/hadoop-yarn-server-common-2.7.5.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.5.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.5.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.5.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.5.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.5.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/mapreduce/lib/asm-3.2.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/mapreduce/lib/guice-3.0.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.5.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/mapreduce/lib/javax.inject-1.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/mapreduce/lib/junit-4.11.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/mapreduce/lib/xz-1.0.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.5.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.5.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.5.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.5.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.5.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.5-tests.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.5.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.5.jar:/Users/michael.wh/workspace/hadoop-2.7.5/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.5.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://shv@git-wip-us.apache.org/repos/asf/hadoop.git -r 18065c2b6806ed4aa6a3187d77cbe21bb3dba075; compiled by 'kshvachk' on 2017-12-16T01:06Z
STARTUP_MSG:   java = 1.8.0_101
************************************************************/
2018-01-23 18:38:29,333 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2018-01-23 18:38:29,718 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2018-01-23 18:38:30,058 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2018-01-23 18:38:30,129 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2018-01-23 18:38:30,129 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2018-01-23 18:38:30,134 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2018-01-23 18:38:30,137 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is 30.28.160.77
2018-01-23 18:38:30,144 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2018-01-23 18:38:30,180 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:50010
2018-01-23 18:38:30,182 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwith is 1048576 bytes/s
2018-01-23 18:38:30,182 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 5
2018-01-23 18:38:30,265 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2018-01-23 18:38:30,274 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2018-01-23 18:38:30,281 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2018-01-23 18:38:30,286 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2018-01-23 18:38:30,287 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2018-01-23 18:38:30,287 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2018-01-23 18:38:30,288 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2018-01-23 18:38:30,302 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 52364
2018-01-23 18:38:30,302 INFO org.mortbay.log: jetty-6.1.26
2018-01-23 18:38:30,460 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:52364
2018-01-23 18:38:30,544 INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:50075
2018-01-23 18:38:30,684 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = michael.wh
2018-01-23 18:38:30,685 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2018-01-23 18:38:30,723 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000
2018-01-23 18:38:30,741 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 50020
2018-01-23 18:38:30,868 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:50020
2018-01-23 18:38:30,885 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2018-01-23 18:38:30,911 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: <default>
2018-01-23 18:38:30,924 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:9000 starting to offer service
2018-01-23 18:38:30,937 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2018-01-23 18:38:30,938 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2018-01-23 18:38:31,308 INFO org.apache.hadoop.hdfs.server.common.Storage: Using 1 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=1, dataDirs=1)
2018-01-23 18:38:31,319 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /tmp/hadoop-michael.wh/dfs/data/in_use.lock acquired by nodename 976@michaeldemacbook-pro.local
2018-01-23 18:38:31,320 INFO org.apache.hadoop.hdfs.server.common.Storage: Storage directory /tmp/hadoop-michael.wh/dfs/data is not formatted for namespace 1050173558. Formatting...
2018-01-23 18:38:31,321 INFO org.apache.hadoop.hdfs.server.common.Storage: Generated new storageID DS-fe02cea5-126a-4e71-96c4-d7f33d6587ac for directory /tmp/hadoop-michael.wh/dfs/data
2018-01-23 18:38:31,379 INFO org.apache.hadoop.hdfs.server.common.Storage: Analyzing storage directories for bpid BP-1000273023-30.28.160.77-1516703871702
2018-01-23 18:38:31,380 INFO org.apache.hadoop.hdfs.server.common.Storage: Locking is disabled for /tmp/hadoop-michael.wh/dfs/data/current/BP-1000273023-30.28.160.77-1516703871702
2018-01-23 18:38:31,380 INFO org.apache.hadoop.hdfs.server.common.Storage: Block pool storage directory /tmp/hadoop-michael.wh/dfs/data/current/BP-1000273023-30.28.160.77-1516703871702 is not formatted for BP-1000273023-30.28.160.77-1516703871702. Formatting ...
2018-01-23 18:38:31,380 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting block pool BP-1000273023-30.28.160.77-1516703871702 directory /tmp/hadoop-michael.wh/dfs/data/current/BP-1000273023-30.28.160.77-1516703871702/current
2018-01-23 18:38:31,381 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Setting up storage: nsid=1050173558;bpid=BP-1000273023-30.28.160.77-1516703871702;lv=-56;nsInfo=lv=-63;cid=CID-5b079230-e5ea-4632-b8b8-f06a0166cc47;nsid=1050173558;c=0;bpid=BP-1000273023-30.28.160.77-1516703871702;dnuuid=null
2018-01-23 18:38:31,382 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Generated and persisted new Datanode UUID e20a2f5e-6007-4e93-a70e-d42ad85a0f82
2018-01-23 18:38:31,422 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added new volume: DS-fe02cea5-126a-4e71-96c4-d7f33d6587ac
2018-01-23 18:38:31,422 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added volume - /tmp/hadoop-michael.wh/dfs/data/current, StorageType: DISK
2018-01-23 18:38:31,428 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Registered FSDatasetState MBean
2018-01-23 18:38:31,429 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding block pool BP-1000273023-30.28.160.77-1516703871702
2018-01-23 18:38:31,430 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Scanning block pool BP-1000273023-30.28.160.77-1516703871702 on volume /tmp/hadoop-michael.wh/dfs/data/current...
2018-01-23 18:38:31,447 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time taken to scan block pool BP-1000273023-30.28.160.77-1516703871702 on /tmp/hadoop-michael.wh/dfs/data/current: 18ms
2018-01-23 18:38:31,447 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to scan all replicas for block pool BP-1000273023-30.28.160.77-1516703871702: 18ms
2018-01-23 18:38:31,448 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding replicas to map for block pool BP-1000273023-30.28.160.77-1516703871702 on volume /tmp/hadoop-michael.wh/dfs/data/current...
2018-01-23 18:38:31,448 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time to add replicas to map for block pool BP-1000273023-30.28.160.77-1516703871702 on volume /tmp/hadoop-michael.wh/dfs/data/current: 0ms
2018-01-23 18:38:31,448 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to add all replicas to map: 1ms
2018-01-23 18:38:31,450 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: Now scanning bpid BP-1000273023-30.28.160.77-1516703871702 on volume /tmp/hadoop-michael.wh/dfs/data
2018-01-23 18:38:31,452 ERROR org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: dfs.datanode.directoryscan.throttle.limit.ms.per.sec set to value below 1 ms/sec. Assuming default value of 1000
2018-01-23 18:38:31,453 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: Periodic Directory Tree Verification scan starting at 1516717892453ms with interval of 21600000ms
2018-01-23 18:38:31,457 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool BP-1000273023-30.28.160.77-1516703871702 (Datanode Uuid null) service to localhost/127.0.0.1:9000 beginning handshake with NN
2018-01-23 18:38:31,467 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop-michael.wh/dfs/data, DS-fe02cea5-126a-4e71-96c4-d7f33d6587ac): finished scanning block pool BP-1000273023-30.28.160.77-1516703871702
2018-01-23 18:38:31,509 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool Block pool BP-1000273023-30.28.160.77-1516703871702 (Datanode Uuid null) service to localhost/127.0.0.1:9000 successfully registered with NN
2018-01-23 18:38:31,509 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: For namenode localhost/127.0.0.1:9000 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2018-01-23 18:38:31,511 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop-michael.wh/dfs/data, DS-fe02cea5-126a-4e71-96c4-d7f33d6587ac): no suitable block pools found to scan.  Waiting 1814399939 ms.
2018-01-23 18:38:31,611 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Namenode Block pool BP-1000273023-30.28.160.77-1516703871702 (Datanode Uuid e20a2f5e-6007-4e93-a70e-d42ad85a0f82) service to localhost/127.0.0.1:9000 trying to claim ACTIVE state with txid=1
2018-01-23 18:38:31,611 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Acknowledging ACTIVE Namenode Block pool BP-1000273023-30.28.160.77-1516703871702 (Datanode Uuid e20a2f5e-6007-4e93-a70e-d42ad85a0f82) service to localhost/127.0.0.1:9000
2018-01-23 18:38:31,675 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x5931d109161c3,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 3 msec to generate and 60 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2018-01-23 18:38:31,675 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-1000273023-30.28.160.77-1516703871702
2018-01-23 18:41:55,494 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1000273023-30.28.160.77-1516703871702:blk_1073741825_1001 src: /127.0.0.1:52427 dest: /127.0.0.1:50010
2018-01-23 18:41:55,609 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:52427, dest: /127.0.0.1:50010, bytes: 4436, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_843731229_1, offset: 0, srvID: e20a2f5e-6007-4e93-a70e-d42ad85a0f82, blockid: BP-1000273023-30.28.160.77-1516703871702:blk_1073741825_1001, duration: 94625293
2018-01-23 18:41:55,610 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1000273023-30.28.160.77-1516703871702:blk_1073741825_1001, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2018-01-23 18:41:56,064 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1000273023-30.28.160.77-1516703871702:blk_1073741826_1002 src: /127.0.0.1:52428 dest: /127.0.0.1:50010
2018-01-23 18:41:56,068 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:52428, dest: /127.0.0.1:50010, bytes: 1335, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_843731229_1, offset: 0, srvID: e20a2f5e-6007-4e93-a70e-d42ad85a0f82, blockid: BP-1000273023-30.28.160.77-1516703871702:blk_1073741826_1002, duration: 2194044
2018-01-23 18:41:56,068 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1000273023-30.28.160.77-1516703871702:blk_1073741826_1002, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2018-01-23 18:41:56,086 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1000273023-30.28.160.77-1516703871702:blk_1073741827_1003 src: /127.0.0.1:52429 dest: /127.0.0.1:50010
2018-01-23 18:41:56,090 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:52429, dest: /127.0.0.1:50010, bytes: 318, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_843731229_1, offset: 0, srvID: e20a2f5e-6007-4e93-a70e-d42ad85a0f82, blockid: BP-1000273023-30.28.160.77-1516703871702:blk_1073741827_1003, duration: 2065873
2018-01-23 18:41:56,090 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1000273023-30.28.160.77-1516703871702:blk_1073741827_1003, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2018-01-23 18:41:56,108 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1000273023-30.28.160.77-1516703871702:blk_1073741828_1004 src: /127.0.0.1:52430 dest: /127.0.0.1:50010
2018-01-23 18:41:56,112 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:52430, dest: /127.0.0.1:50010, bytes: 883, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_843731229_1, offset: 0, srvID: e20a2f5e-6007-4e93-a70e-d42ad85a0f82, blockid: BP-1000273023-30.28.160.77-1516703871702:blk_1073741828_1004, duration: 2140664
2018-01-23 18:41:56,112 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1000273023-30.28.160.77-1516703871702:blk_1073741828_1004, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2018-01-23 18:41:56,131 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1000273023-30.28.160.77-1516703871702:blk_1073741829_1005 src: /127.0.0.1:52431 dest: /127.0.0.1:50010
2018-01-23 18:41:56,134 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:52431, dest: /127.0.0.1:50010, bytes: 3670, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_843731229_1, offset: 0, srvID: e20a2f5e-6007-4e93-a70e-d42ad85a0f82, blockid: BP-1000273023-30.28.160.77-1516703871702:blk_1073741829_1005, duration: 1850758
2018-01-23 18:41:56,134 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1000273023-30.28.160.77-1516703871702:blk_1073741829_1005, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2018-01-23 18:41:56,151 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1000273023-30.28.160.77-1516703871702:blk_1073741830_1006 src: /127.0.0.1:52432 dest: /127.0.0.1:50010
2018-01-23 18:41:56,155 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:52432, dest: /127.0.0.1:50010, bytes: 4224, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_843731229_1, offset: 0, srvID: e20a2f5e-6007-4e93-a70e-d42ad85a0f82, blockid: BP-1000273023-30.28.160.77-1516703871702:blk_1073741830_1006, duration: 2021185
2018-01-23 18:41:56,155 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1000273023-30.28.160.77-1516703871702:blk_1073741830_1006, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2018-01-23 18:41:56,170 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1000273023-30.28.160.77-1516703871702:blk_1073741831_1007 src: /127.0.0.1:52433 dest: /127.0.0.1:50010
2018-01-23 18:41:56,175 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:52433, dest: /127.0.0.1:50010, bytes: 2490, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_843731229_1, offset: 0, srvID: e20a2f5e-6007-4e93-a70e-d42ad85a0f82, blockid: BP-1000273023-30.28.160.77-1516703871702:blk_1073741831_1007, duration: 2914363
2018-01-23 18:41:56,175 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1000273023-30.28.160.77-1516703871702:blk_1073741831_1007, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2018-01-23 18:41:56,191 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1000273023-30.28.160.77-1516703871702:blk_1073741832_1008 src: /127.0.0.1:52434 dest: /127.0.0.1:50010
2018-01-23 18:41:56,195 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:52434, dest: /127.0.0.1:50010, bytes: 2598, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_843731229_1, offset: 0, srvID: e20a2f5e-6007-4e93-a70e-d42ad85a0f82, blockid: BP-1000273023-30.28.160.77-1516703871702:blk_1073741832_1008, duration: 2360698
2018-01-23 18:41:56,195 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1000273023-30.28.160.77-1516703871702:blk_1073741832_1008, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2018-01-23 18:41:56,212 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1000273023-30.28.160.77-1516703871702:blk_1073741833_1009 src: /127.0.0.1:52435 dest: /127.0.0.1:50010
2018-01-23 18:41:56,216 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:52435, dest: /127.0.0.1:50010, bytes: 9683, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_843731229_1, offset: 0, srvID: e20a2f5e-6007-4e93-a70e-d42ad85a0f82, blockid: BP-1000273023-30.28.160.77-1516703871702:blk_1073741833_1009, duration: 2121178
2018-01-23 18:41:56,216 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1000273023-30.28.160.77-1516703871702:blk_1073741833_1009, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2018-01-23 18:41:56,231 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1000273023-30.28.160.77-1516703871702:blk_1073741834_1010 src: /127.0.0.1:52436 dest: /127.0.0.1:50010
2018-01-23 18:41:56,237 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:52436, dest: /127.0.0.1:50010, bytes: 867, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_843731229_1, offset: 0, srvID: e20a2f5e-6007-4e93-a70e-d42ad85a0f82, blockid: BP-1000273023-30.28.160.77-1516703871702:blk_1073741834_1010, duration: 3638609
2018-01-23 18:41:56,237 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1000273023-30.28.160.77-1516703871702:blk_1073741834_1010, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2018-01-23 18:41:56,252 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1000273023-30.28.160.77-1516703871702:blk_1073741835_1011 src: /127.0.0.1:52437 dest: /127.0.0.1:50010
2018-01-23 18:41:56,256 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:52437, dest: /127.0.0.1:50010, bytes: 1449, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_843731229_1, offset: 0, srvID: e20a2f5e-6007-4e93-a70e-d42ad85a0f82, blockid: BP-1000273023-30.28.160.77-1516703871702:blk_1073741835_1011, duration: 2541300
2018-01-23 18:41:56,256 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1000273023-30.28.160.77-1516703871702:blk_1073741835_1011, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2018-01-23 18:41:56,271 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1000273023-30.28.160.77-1516703871702:blk_1073741836_1012 src: /127.0.0.1:52438 dest: /127.0.0.1:50010
2018-01-23 18:41:56,275 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:52438, dest: /127.0.0.1:50010, bytes: 1657, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_843731229_1, offset: 0, srvID: e20a2f5e-6007-4e93-a70e-d42ad85a0f82, blockid: BP-1000273023-30.28.160.77-1516703871702:blk_1073741836_1012, duration: 2502750
2018-01-23 18:41:56,275 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1000273023-30.28.160.77-1516703871702:blk_1073741836_1012, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2018-01-23 18:41:56,291 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1000273023-30.28.160.77-1516703871702:blk_1073741837_1013 src: /127.0.0.1:52439 dest: /127.0.0.1:50010
2018-01-23 18:41:56,295 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:52439, dest: /127.0.0.1:50010, bytes: 21, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_843731229_1, offset: 0, srvID: e20a2f5e-6007-4e93-a70e-d42ad85a0f82, blockid: BP-1000273023-30.28.160.77-1516703871702:blk_1073741837_1013, duration: 1851666
2018-01-23 18:41:56,295 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1000273023-30.28.160.77-1516703871702:blk_1073741837_1013, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2018-01-23 18:41:56,310 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1000273023-30.28.160.77-1516703871702:blk_1073741838_1014 src: /127.0.0.1:52440 dest: /127.0.0.1:50010
2018-01-23 18:41:56,313 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:52440, dest: /127.0.0.1:50010, bytes: 620, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_843731229_1, offset: 0, srvID: e20a2f5e-6007-4e93-a70e-d42ad85a0f82, blockid: BP-1000273023-30.28.160.77-1516703871702:blk_1073741838_1014, duration: 1892440
2018-01-23 18:41:56,314 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1000273023-30.28.160.77-1516703871702:blk_1073741838_1014, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2018-01-23 18:41:56,328 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1000273023-30.28.160.77-1516703871702:blk_1073741839_1015 src: /127.0.0.1:52441 dest: /127.0.0.1:50010
2018-01-23 18:41:56,332 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:52441, dest: /127.0.0.1:50010, bytes: 3518, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_843731229_1, offset: 0, srvID: e20a2f5e-6007-4e93-a70e-d42ad85a0f82, blockid: BP-1000273023-30.28.160.77-1516703871702:blk_1073741839_1015, duration: 2092626
2018-01-23 18:41:56,332 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1000273023-30.28.160.77-1516703871702:blk_1073741839_1015, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2018-01-23 18:41:56,349 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1000273023-30.28.160.77-1516703871702:blk_1073741840_1016 src: /127.0.0.1:52442 dest: /127.0.0.1:50010
2018-01-23 18:41:56,353 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:52442, dest: /127.0.0.1:50010, bytes: 1527, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_843731229_1, offset: 0, srvID: e20a2f5e-6007-4e93-a70e-d42ad85a0f82, blockid: BP-1000273023-30.28.160.77-1516703871702:blk_1073741840_1016, duration: 2275163
2018-01-23 18:41:56,353 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1000273023-30.28.160.77-1516703871702:blk_1073741840_1016, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2018-01-23 18:41:56,777 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1000273023-30.28.160.77-1516703871702:blk_1073741841_1017 src: /127.0.0.1:52443 dest: /127.0.0.1:50010
2018-01-23 18:41:56,781 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:52443, dest: /127.0.0.1:50010, bytes: 1631, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_843731229_1, offset: 0, srvID: e20a2f5e-6007-4e93-a70e-d42ad85a0f82, blockid: BP-1000273023-30.28.160.77-1516703871702:blk_1073741841_1017, duration: 1854009
2018-01-23 18:41:56,781 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1000273023-30.28.160.77-1516703871702:blk_1073741841_1017, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2018-01-23 18:41:56,798 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1000273023-30.28.160.77-1516703871702:blk_1073741842_1018 src: /127.0.0.1:52444 dest: /127.0.0.1:50010
2018-01-23 18:41:56,802 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:52444, dest: /127.0.0.1:50010, bytes: 5540, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_843731229_1, offset: 0, srvID: e20a2f5e-6007-4e93-a70e-d42ad85a0f82, blockid: BP-1000273023-30.28.160.77-1516703871702:blk_1073741842_1018, duration: 2135762
2018-01-23 18:41:56,802 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1000273023-30.28.160.77-1516703871702:blk_1073741842_1018, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2018-01-23 18:41:56,817 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1000273023-30.28.160.77-1516703871702:blk_1073741843_1019 src: /127.0.0.1:52445 dest: /127.0.0.1:50010
2018-01-23 18:41:56,821 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:52445, dest: /127.0.0.1:50010, bytes: 11237, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_843731229_1, offset: 0, srvID: e20a2f5e-6007-4e93-a70e-d42ad85a0f82, blockid: BP-1000273023-30.28.160.77-1516703871702:blk_1073741843_1019, duration: 2214878
2018-01-23 18:41:56,821 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1000273023-30.28.160.77-1516703871702:blk_1073741843_1019, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2018-01-23 18:41:56,837 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1000273023-30.28.160.77-1516703871702:blk_1073741844_1020 src: /127.0.0.1:52446 dest: /127.0.0.1:50010
2018-01-23 18:41:56,841 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:52446, dest: /127.0.0.1:50010, bytes: 951, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_843731229_1, offset: 0, srvID: e20a2f5e-6007-4e93-a70e-d42ad85a0f82, blockid: BP-1000273023-30.28.160.77-1516703871702:blk_1073741844_1020, duration: 2199647
2018-01-23 18:41:56,841 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1000273023-30.28.160.77-1516703871702:blk_1073741844_1020, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2018-01-23 18:41:56,859 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1000273023-30.28.160.77-1516703871702:blk_1073741845_1021 src: /127.0.0.1:52447 dest: /127.0.0.1:50010
2018-01-23 18:41:56,864 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:52447, dest: /127.0.0.1:50010, bytes: 1383, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_843731229_1, offset: 0, srvID: e20a2f5e-6007-4e93-a70e-d42ad85a0f82, blockid: BP-1000273023-30.28.160.77-1516703871702:blk_1073741845_1021, duration: 3402346
2018-01-23 18:41:56,865 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1000273023-30.28.160.77-1516703871702:blk_1073741845_1021, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2018-01-23 18:41:57,288 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1000273023-30.28.160.77-1516703871702:blk_1073741846_1022 src: /127.0.0.1:52448 dest: /127.0.0.1:50010
2018-01-23 18:41:57,292 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:52448, dest: /127.0.0.1:50010, bytes: 4113, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_843731229_1, offset: 0, srvID: e20a2f5e-6007-4e93-a70e-d42ad85a0f82, blockid: BP-1000273023-30.28.160.77-1516703871702:blk_1073741846_1022, duration: 2022169
2018-01-23 18:41:57,293 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1000273023-30.28.160.77-1516703871702:blk_1073741846_1022, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2018-01-23 18:41:57,307 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1000273023-30.28.160.77-1516703871702:blk_1073741847_1023 src: /127.0.0.1:52449 dest: /127.0.0.1:50010
2018-01-23 18:41:57,310 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:52449, dest: /127.0.0.1:50010, bytes: 758, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_843731229_1, offset: 0, srvID: e20a2f5e-6007-4e93-a70e-d42ad85a0f82, blockid: BP-1000273023-30.28.160.77-1516703871702:blk_1073741847_1023, duration: 1413374
2018-01-23 18:41:57,310 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1000273023-30.28.160.77-1516703871702:blk_1073741847_1023, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2018-01-23 18:41:57,324 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1000273023-30.28.160.77-1516703871702:blk_1073741848_1024 src: /127.0.0.1:52450 dest: /127.0.0.1:50010
2018-01-23 18:41:57,327 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:52450, dest: /127.0.0.1:50010, bytes: 10, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_843731229_1, offset: 0, srvID: e20a2f5e-6007-4e93-a70e-d42ad85a0f82, blockid: BP-1000273023-30.28.160.77-1516703871702:blk_1073741848_1024, duration: 1402440
2018-01-23 18:41:57,327 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1000273023-30.28.160.77-1516703871702:blk_1073741848_1024, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2018-01-23 18:41:57,340 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1000273023-30.28.160.77-1516703871702:blk_1073741849_1025 src: /127.0.0.1:52451 dest: /127.0.0.1:50010
2018-01-23 18:41:57,343 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:52451, dest: /127.0.0.1:50010, bytes: 2316, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_843731229_1, offset: 0, srvID: e20a2f5e-6007-4e93-a70e-d42ad85a0f82, blockid: BP-1000273023-30.28.160.77-1516703871702:blk_1073741849_1025, duration: 1580791
2018-01-23 18:41:57,343 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1000273023-30.28.160.77-1516703871702:blk_1073741849_1025, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2018-01-23 18:41:57,359 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1000273023-30.28.160.77-1516703871702:blk_1073741850_1026 src: /127.0.0.1:52452 dest: /127.0.0.1:50010
2018-01-23 18:41:57,362 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:52452, dest: /127.0.0.1:50010, bytes: 2697, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_843731229_1, offset: 0, srvID: e20a2f5e-6007-4e93-a70e-d42ad85a0f82, blockid: BP-1000273023-30.28.160.77-1516703871702:blk_1073741850_1026, duration: 1502597
2018-01-23 18:41:57,363 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1000273023-30.28.160.77-1516703871702:blk_1073741850_1026, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2018-01-23 18:41:57,376 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1000273023-30.28.160.77-1516703871702:blk_1073741851_1027 src: /127.0.0.1:52453 dest: /127.0.0.1:50010
2018-01-23 18:41:57,379 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:52453, dest: /127.0.0.1:50010, bytes: 2191, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_843731229_1, offset: 0, srvID: e20a2f5e-6007-4e93-a70e-d42ad85a0f82, blockid: BP-1000273023-30.28.160.77-1516703871702:blk_1073741851_1027, duration: 1688066
2018-01-23 18:41:57,380 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1000273023-30.28.160.77-1516703871702:blk_1073741851_1027, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2018-01-23 18:41:57,394 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1000273023-30.28.160.77-1516703871702:blk_1073741852_1028 src: /127.0.0.1:52454 dest: /127.0.0.1:50010
2018-01-23 18:41:57,397 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:52454, dest: /127.0.0.1:50010, bytes: 4567, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_843731229_1, offset: 0, srvID: e20a2f5e-6007-4e93-a70e-d42ad85a0f82, blockid: BP-1000273023-30.28.160.77-1516703871702:blk_1073741852_1028, duration: 1284698
2018-01-23 18:41:57,397 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1000273023-30.28.160.77-1516703871702:blk_1073741852_1028, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2018-01-23 18:41:57,410 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1000273023-30.28.160.77-1516703871702:blk_1073741853_1029 src: /127.0.0.1:52455 dest: /127.0.0.1:50010
2018-01-23 18:41:57,413 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:52455, dest: /127.0.0.1:50010, bytes: 690, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_843731229_1, offset: 0, srvID: e20a2f5e-6007-4e93-a70e-d42ad85a0f82, blockid: BP-1000273023-30.28.160.77-1516703871702:blk_1073741853_1029, duration: 1280611
2018-01-23 18:41:57,413 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1000273023-30.28.160.77-1516703871702:blk_1073741853_1029, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
